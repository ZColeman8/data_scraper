# ğŸ•¸ï¸ RemoteOK Job Scraper

A Python automation project that scrapes remote job listings from [RemoteOK](https://remoteok.com), saves them to a CSV file, and generates a summary report highlighting the top hiring companies and most in-demand skills.

---

## ğŸš€ Features

- Scrapes live remote jobs using RemoteOKâ€™s public API
- Saves job data to a CSV file
- Generates a human-readable text summary report
- Uses structured logging throughout the project
- Includes automated tests using `pytest`
- Generates a Pytest HTML report
- Integrated with GitHub Actions for Continuous Integration (CI)

---

## ğŸ› ï¸ Tech Stack

- Python 3.11
- `requests` for API calls
- `csv` for file handling
- `collections.Counter` for frequency analysis
- `logging` for log tracking
- `pytest` for testing
- GitHub Actions for CI

---

## ğŸ“ Project Structure

```
data_scraper/
â”œâ”€â”€ data/                        # Stores the generated jobs.csv file
â”œâ”€â”€ reports/                     # Contains the generated summary_report.txt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraper.py               # Main scraping logic
â”‚   â”œâ”€â”€ report_generator.py      # Generates text summary report
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ file_writer.py       # CSV export functionality
â”‚       â”œâ”€â”€ logger.py            # Logging setup
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_scraper.py          # Pytest-based unit tests
â”œâ”€â”€ main.py                      # Entry point for the scraper workflow
â”œâ”€â”€ requirements.txt             # Required packages
â”œâ”€â”€ pytest.ini                   # Pytest configuration
â””â”€â”€ .github/workflows/ci.yml     # GitHub Actions workflow for CI
```

---

## ğŸ§ª Running the Project

### â–¶ï¸ Run the Scraper

This command will:
- Scrape job listings from RemoteOK
- Save them to `data/jobs.csv`
- Generate a summary text report in `reports/summary_report.txt`

```bash
python main.py
```

### ğŸ§ª Run Tests

All tests can be executed using:

```bash
pytest
```

Pytest will run test validations and check the output file structure.

---

## ğŸ“ Sample Summary Output

```
ğŸ“Š Total jobs scraped: 99

ğŸ¢ Top Hiring Companies:
- TransPerfect: 4 job(s)
- Tether Operations Limited: 4 job(s)
- TELUS Digital: 2 job(s)
- Arbitrum Foundation: 2 job(s)
- ModelVault: 2 job(s)

ğŸ·ï¸ Most In-Demand Tags:
- support: 36 job(s)
- digital nomad: 31 job(s)
- senior: 28 job(s)
- technical: 27 job(s)
- engineer: 27 job(s)
```

---

## ğŸ“‹ Logging

Logs provide real-time visibility into the scraping and file generation process.

Example:
```
INFO - Starting job scraping workflow...
INFO - Saving 99 jobs to data/jobs.csv...
INFO - âœ… Jobs successfully saved to data/jobs.csv
INFO - Generating summary report...
INFO - Summary report saved to reports/summary_report.txt
INFO - Job scraping workflow completed successfully.
```

---

## ğŸ”„ Continuous Integration (CI)

CI is set up with **GitHub Actions** to automatically run tests on every push to `main`.

Youâ€™ll find the workflow config in:

```
.github/workflows/ci.yml
```

It installs dependencies, runs `pytest`, and uploads the HTML report artifact.

---

## ğŸ“¦ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/data_scraper.git
cd data_scraper
```

### 2. Create a Virtual Environment (Optional)

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Requirements

```bash
pip install -r requirements.txt
```

---

## ğŸ§¼ .gitignore

Your `.gitignore` should include:

```
__pycache__/
*.pyc
.env
data/
reports/
```

---

## ğŸ“ƒ License

This project is for educational and portfolio use. Attribution appreciated if reused.

---

## ğŸ‘¨â€ğŸ’» Author

**Zach Coleman**  
QA Automation Engineer in Training

---

## ğŸ™Œ Acknowledgements

- [RemoteOK](https://remoteok.com) â€” for making job listings publicly accessible.
